# app.py
import streamlit as st
from pathlib import Path
from PIL import Image
import uuid, re, os, json, shutil
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

from runway_api import generate_video_from_image, extract_video_url
from video_utils import download_video, concat_videos, add_subtitle_to_video, trim_video_to_duration
# TTS ëª¨ë“ˆ ìºì‹± ë°©ì§€ - í•­ìƒ ìµœì‹  ì½”ë“œ ë¡œë“œ
import importlib
import tts_module
importlib.reload(tts_module)
from tts_module import (
    generate_audio_for_subtitles,  # GPT ë°°ì • í™”ì ì§€ì› + ë‚˜ë˜ì´ì…˜/ëŒ€ì‚¬ ë¶„ë¦¬
    add_audio_to_video,
    concat_videos_with_audio,
    get_audio_duration
)
import re
import json
# OpenAI í´ë¼ì´ì–¸íŠ¸
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

import b_text_based

# --------------------------------
# Streamlit UI ì„¤ì •
# --------------------------------
st.set_page_config(page_title="AI ìˆì¸  ìƒì„±ê¸°", layout="wide")
st.title(" ì‚½í™” ê¸°ë°˜ AI ìˆì¸  ìƒì„±ê¸° + ìë§‰ ì˜¤ë²„ë ˆì´ (Runway Gen4)")

# --------------------------------
# ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
# --------------------------------
BASE_DIR = Path(__file__).resolve().parent
CHARACTER_DIR = BASE_DIR / "character"
TXT_DIR = CHARACTER_DIR / "txt" / "048"

# --------------------------------
# ğŸ—‚ Session State
# --------------------------------
if "loaded_images" not in st.session_state:
    st.session_state.loaded_images = []
if "selected_pages" not in st.session_state:
    st.session_state.selected_pages = []
if "current_book" not in st.session_state:
    st.session_state.current_book = None

# --------------------------------
#  ì±… ì„ íƒ
# --------------------------------
# character í´ë”ì—ì„œ ì±… ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (txt, json í´ë” ì œì™¸)
book_folders = [f.name for f in CHARACTER_DIR.iterdir()
                if f.is_dir() and f.name not in ["txt", "json"]]
book_folders = sorted(book_folders)

if not book_folders:
    st.error("character í´ë”ì— ì±…ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

selected_book = st.selectbox("ì±… ì„ íƒ:", book_folders)

# ì±…ì´ ë³€ê²½ë˜ë©´ ì´ë¯¸ì§€ ëª©ë¡ ì´ˆê¸°í™”
if st.session_state.current_book != selected_book:
    st.session_state.current_book = selected_book
    st.session_state.loaded_images = []
    st.session_state.selected_pages = []

# ì´ë¯¸ì§€ í´ë”ì™€ txt íŒŒì¼ ìë™ ì„¤ì •
folder = CHARACTER_DIR / selected_book
txt_file = TXT_DIR / f"{selected_book}.txt"

if not folder.exists():
    st.error(f"ì´ë¯¸ì§€ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder}")
    st.stop()

if not txt_file.exists():
    st.warning(f" txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {txt_file.name}")

# --------------------------------
# ğŸ–¼ ì‚½í™” ë¡œë“œ (ì¸ë„¤ì¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½)
# --------------------------------
THUMBNAIL_SIZE = (200, 200)

@st.cache_data(show_spinner=False)
def load_images(folder_path: str):
    folder = Path(folder_path)
    results = []
    for p in sorted(folder.iterdir()):
        if p.suffix.lower() in {".png", ".jpg", ".jpeg"}:
            img = Image.open(p)
            img.thumbnail(THUMBNAIL_SIZE)  # Resize to thumbnail
            results.append((p.name, img.copy()))
            img.close()
    return results

if not st.session_state.loaded_images:
    st.session_state.loaded_images = load_images(str(folder))

images = st.session_state.loaded_images
st.success(f" {len(images)}ê°œì˜ ì‚½í™” ë¡œë“œ ì™„ë£Œ")


#-----------------
# 0. ì‘ì—… ë°©ì‹ ì„ íƒ
#------------------
st.divider()
st.subheader("0.ì‘ì—… ë°©ì‹ ì„ íƒ")

mode = st.radio(
    "ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì˜ìƒì„ ë§Œë“œì‹œê² ìŠµë‹ˆê¹Œ?",
    ["(ê¸°ì¡´) ì´ë¯¸ì§€ ì„ íƒ ê¸°ë°˜ ì œì‘", "(ì‹ ê·œ) í…ìŠ¤íŠ¸ ë¶„ì„ ê¸°ë°˜ ì˜ˆê³ í¸ ì œì‘"],
    captions=["ë‚´ê°€ ê³ ë¥¸ ì‚½í™”ì— ë§ì¶° ëŒ€ë³¸ì„ ì”ë‹ˆë‹¤.", "ì „ì²´ ë‚´ìš©ì„ ìš”ì•½í•´ ì˜ˆê³ í¸ì„ ì§œê³ , ì–´ìš¸ë¦¬ëŠ” ê·¸ë¦¼ì„ AIê°€ ì¶”ì²œí•©ë‹ˆë‹¤."]
)

# ëª¨ë“œ ë³€ê²½ ì‹œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (í•„ìš”ì‹œ)
if "current_mode" not in st.session_state:
    st.session_state.current_mode = mode

if st.session_state.current_mode != mode:
    st.session_state.current_mode = mode
    # ì—¬ê¸°ì— ëª¨ë“œ ë³€ê²½ ì‹œ ì´ˆê¸°í™”í•  ë³€ìˆ˜ë“¤ ë¦¬ì…‹ (ì˜ˆ: loaded_images ë“±)
    st.session_state.selected_pages = []
    st.rerun()

#-------------------------------
# A. ê¸°ì¡´ ì´ë¯¸ì§€ ì„ íƒ ê¸°ë°˜ ì œì‘
#-----------------------------
if mode == "(ê¸°ì¡´) ì´ë¯¸ì§€ ì„ íƒ ê¸°ë°˜ ì œì‘":
    st.info(" ë§ˆìŒì— ë“œëŠ” ì‚½í™”ë¥¼ ë¨¼ì € ê³ ë¥´ë©´, AIê°€ ì´ì•¼ê¸°ë¥¼ ì´ì–´ì¤ë‹ˆë‹¤.")
    # --------------------------------
    # â‘  ì‚½í™” ì„ íƒ
    # --------------------------------
    st.subheader("â‘  ì‚¬ìš©í•  ì‚½í™” ì„ íƒ")

    with st.form("select_form"):
        cols = st.columns(6)
        selected = list(st.session_state.selected_pages)

        for i, (name, img) in enumerate(images):
            with cols[i % 6]:
                st.image(img, use_container_width=True)
                if st.checkbox(name, name in selected, key=f"chk_{name}"):
                    if name not in selected:
                        selected.append(name)
                else:
                    if name in selected:
                        selected.remove(name)

        if st.form_submit_button(" ì„ íƒ í™•ì •", type="primary"):
            st.session_state.selected_pages = selected

    # ì„ íƒëœ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°
    if not st.session_state.selected_pages:
        st.info("ì•„ì§ ì„ íƒí•œ ì‚½í™”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # --------------------------------
    # â‘¡ ì˜ìƒ ì˜µì…˜ ì„¤ì •
    # --------------------------------
    st.divider()
    st.subheader("â‘¡ Runway í”„ë¡¬í”„íŠ¸ & ê¸¸ì´")

    PROMPT = st.text_input(" ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸:", "gentle cinematic movement, children's book illustration")
    DEFAULT_DURATION = st.slider("ğŸ–¼ ìë§‰ ì—†ëŠ” ì¥ë©´ ê¸°ë³¸ ê¸¸ì´(ì´ˆ):", 3, 5, 5)
    st.info(" ìë§‰ ìˆëŠ” ì¥ë©´ì€ TTS ìŒì„± ê¸¸ì´ì— ë§ì¶° ìë™ ì¡°ì ˆë©ë‹ˆë‹¤.")

    # BGM ì„¤ì •
    st.divider()
    st.subheader("ğŸµ ë°°ê²½ìŒì•…(BGM) ì„¤ì •")

    # BGM í´ë” ì´ë¦„ ë§¤í•‘ (ê¸´ í´ë”ëª… -> ì§§ì€ BGM í´ë”ëª…)
    def get_bgm_folder_name(full_name):
        """ê¸´ ì±… í´ë”ëª…ì—ì„œ BGM í´ë”ëª… ì¶”ì¶œ"""
        bgm_mapping = {
            "ê³ ìŠ´ë„ì¹˜ì™€ë¾°ì¡±í•œê°€ì‹œ": "ê³ ìŠ´ë„ì¹˜ì˜ ë¾°ì¡±í•œ ê°€ì‹œ",
            "ê½ì§€ë‹·ë°œì£¼ë‘¥ì´ë‹·ë°œ": "ê½ì§€ ë‹· ë°œ ì£¼ë‘¥ì´ ë‹· ë°œ",
        }
        for key, value in bgm_mapping.items():
            if key.replace(" ", "") in full_name.replace(" ", ""):
                return value
        return full_name

    bgm_folder_name = get_bgm_folder_name(selected_book)
    BGM_DIR = BASE_DIR / "BGM" / bgm_folder_name

    def get_bgm_for_page(page_name: str, bgm_dir: Path):
        """í˜ì´ì§€ ì´ë¦„ì—ì„œ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•˜ì—¬ í•´ë‹¹í•˜ëŠ” BGM íŒŒì¼ ì°¾ê¸°"""
        if not bgm_dir.exists():
            return None

        # page_006.png -> 6
        match = re.search(r"page_(\d+)", page_name)
        if not match:
            return None
        page_num = int(match.group(1))

        # BGM í´ë”ì—ì„œ í•´ë‹¹ í˜ì´ì§€ ë²ˆí˜¸ì˜ íŒŒì¼ ì°¾ê¸°
        # ì˜ˆ: ê³ ìŠ´ë„ì¹˜ì˜ ë¾°ì¡±í•œ ê°€ì‹œ_6Pìˆ˜ì •.wav ë˜ëŠ” _06Pìˆ˜ì •.wav
        for bgm_file in bgm_dir.iterdir():
            if bgm_file.suffix.lower() not in ['.wav', '.mp3']:
                continue
            # _ìˆ«ìP íŒ¨í„´ ì°¾ê¸°
            bgm_match = re.search(r'_(\d+)P', bgm_file.name)
            if bgm_match and int(bgm_match.group(1)) == page_num:
                return bgm_file

        return None

    use_bgm = st.checkbox("ë°°ê²½ìŒì•… ì‚¬ìš© (í˜ì´ì§€ë³„ ìë™ ë§¤ì¹­)", value=False)
    bgm_volume = 0.15

    if use_bgm:
        if BGM_DIR.exists():
            bgm_files = sorted([f.name for f in BGM_DIR.iterdir() if f.suffix.lower() in ['.wav', '.mp3']])
            if bgm_files:
                bgm_volume = st.slider("BGM ë³¼ë¥¨ (%):", 5, 50, 15) / 100.0
                st.info(f" BGM í´ë” ë°œê²¬: {len(bgm_files)}ê°œ íŒŒì¼")
                st.caption("ê° í˜ì´ì§€ ë²ˆí˜¸ì— ë§ëŠ” BGMì´ ìë™ìœ¼ë¡œ ì„ íƒë©ë‹ˆë‹¤.")
            else:
                st.warning(f"BGM í´ë”ì— ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {BGM_DIR}")
                use_bgm = False
        else:
            st.warning(f"BGM í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {BGM_DIR}")
            use_bgm = False

    # --------------------------------
    # TXT ë§¤ì¹­ í•¨ìˆ˜
    # --------------------------------
    def extract_text_for_image(page_name: str, txt_path: Path):
        """
        ì´ë¯¸ì§€ ì´ë¦„(ì˜ˆ: page_006.png)ì—ì„œ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•˜ê³ ,
        txt íŒŒì¼ ë‚´ì—ì„œ í•´ë‹¹ í˜ì´ì§€(--- Page 6 ---)ì˜ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
        """
        if not txt_path.exists():
            return ""

        m = re.search(r"page_(\d+)", page_name)
        if not m:
            return ""
        page_num = int(m.group(1))  # "006" -> 6

        txt_content = txt_path.read_text(encoding="utf-8")

        # --- Page N --- í˜•ì‹ì—ì„œ í•´ë‹¹ í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        pattern = rf"--- Page {page_num} ---\n(.*?)(?=--- Page \d+ ---|$)"
        match = re.search(pattern, txt_content, re.DOTALL)
        if match:
            return match.group(1).strip()
        return ""


    # --------------------------------
    # OpenAIë¡œ ì˜ˆê³ í¸ ìë§‰ + í™”ì ìƒì„±
    # --------------------------------
    def generate_trailer_subtitles_with_speakers(page_texts: list[tuple[str, str]], duration_per_clip: int):
        """
        ê° í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ ì˜ˆê³ í¸ ìŠ¤íƒ€ì¼ ìë§‰ + í™”ì ìƒì„±
        GPTê°€ ë¬¸ë§¥ì„ ì´í•´í•˜ê³  ì ì ˆí•œ í™”ìë¥¼ ë°°ì •í•¨

        Args:
            page_texts: [(page_name, text), ...]
            duration_per_clip: ê° í´ë¦½ì˜ ê¸¸ì´(ì´ˆ)

        Returns:
            list of {"text": str, "speaker": str}
        """
        # í˜ì´ì§€ë³„ ë‚´ìš© ì •ë¦¬
        content_info = "\n".join([
            f"[ì¥ë©´ {i+1} - {name}]: {text[:200]}..."
            if text and len(text) > 200
            else f"[ì¥ë©´ {i+1} - {name}]: {text}" if text
            else f"[ì¥ë©´ {i+1} - {name}]: (ê·¸ë¦¼ë§Œ ìˆëŠ” í˜ì´ì§€ - ìë§‰ ë¶ˆí•„ìš”)"
            for i, (name, text) in enumerate(page_texts)
        ])

        num_scenes = len(page_texts)

        prompt = f"""ë‹¹ì‹ ì€ ë™í™”ì±… ì˜ˆê³ í¸ ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤. ì‹œì²­ìê°€ "ì´ ì±… ë³´ê³  ì‹¶ë‹¤!"ê³  ëŠë¼ê²Œ ë§Œë“œì„¸ìš”.

    ## ì¥ë©´ ì •ë³´ ({num_scenes}ê°œ)
    {content_info}

    ---

    ## ì˜ˆê³ í¸ ìë§‰ ì‘ì„± ê·œì¹™

    ### 1. ê¸°ë³¸ ê·œì¹™
    - ì •í™•íˆ **{num_scenes}ê°œ** ìë§‰ (ì¥ë©´ë‹¹ 1ê°œ, ìˆœì„œ ìœ ì§€!)
    - **ê·¸ë¦¼ë§Œ ìˆëŠ” í˜ì´ì§€** â†’ text: "", speaker: "none"
    - ìë§‰ ê¸¸ì´: **35~60ì** (í’ì„±í•˜ê³  ìƒë™ê° ìˆê²Œ!)
    - ë§íˆ¬: ë™í™”ì±… ì½ì–´ì£¼ëŠ” ëŠë‚Œ (~í–ˆì–´ìš”, ~ì´ì—ˆë‹µë‹ˆë‹¤, ~ì˜€ì§€ìš”)

    ### 2.  ì ˆëŒ€ ê¸ˆì§€ - ê²°ë§ ìŠ¤í¬ì¼ëŸ¬!
    -  "ì‚¼êµ­ í†µì¼ì„ ì´ë¤˜ìŠµë‹ˆë‹¤" â†’ ê²°ë§ ë…¸ì¶œ!
    -  "í–‰ë³µí•˜ê²Œ ì‚´ì•˜ë‹µë‹ˆë‹¤" â†’ í•´í”¼ì—”ë”© ìŠ¤í¬ì¼ëŸ¬!
    -  "ë¬¸ì œê°€ í•´ê²°ë˜ì—ˆì–´ìš”" â†’ ê²°ê³¼ ê³µê°œ!

    ### 3.  ë§ˆì§€ë§‰ ìë§‰ì€ ë°˜ë“œì‹œ ê¶ê¸ˆì¦ ìœ ë°œ!
    - "ê³¼ì—° ì›ì´ëŠ” ì™•ê±´ì„ ë§Œë‚  ìˆ˜ ìˆì„ê¹Œìš”?"
    - "ìš´ëª…ì˜ ê·¸ ë‚ , ë¬´ìŠ¨ ì¼ì´ ë²Œì–´ì§ˆê¹Œìš”?"
    - "ìœ„ê¸°ì— ë¹ ì§„ ì£¼ì¸ê³µ! ì–´ë–»ê²Œ ë ê¹Œìš”?"

    ### 4. ìë§‰ ìŠ¤íƒ€ì¼ ì˜ˆì‹œ
    ë‚˜ìœ ì˜ˆ: "ë¬´ëŸ‰ìˆ˜ì „ì—ì„œ ì™•ê±´ì„ ë§Œë‚¬ì–´ìš”." (ë„ˆë¬´ ë°‹ë°‹)
    ì¢‹ì€ ì˜ˆ: "ì²œë…„ê³ ì°° ë¬´ëŸ‰ìˆ˜ì „, ê·¸ê³³ì—ì„œ ìš´ëª…ì ì¸ ë§Œë‚¨ì´ ê¸°ë‹¤ë¦¬ê³  ìˆì—ˆì–´ìš”!"

    ë‚˜ìœ ì˜ˆ: "ì›ì´ëŠ” ê³„ë‹¨ì„ ì˜¬ëìŠµë‹ˆë‹¤." (ë‹¨ìˆœ ì„¤ëª…)
    ì¢‹ì€ ì˜ˆ: "ê°€íŒŒë¥¸ ë°±íŒ” ê³„ë‹¨ì„ ì˜¤ë¥´ëŠ” ì›ì´, ìˆ¨ì´ í„±ê¹Œì§€ ì°¨ì˜¬ëì§€ìš”!"

    ---

    ## í™”ì(speaker) ë°°ì • - í•µì‹¬!

    ### í•µì‹¬ ì›ì¹™: ë‚˜ë ˆì´ì…˜ vs ì§ì ‘ ëŒ€ì‚¬

    **narrator (ë‚´ë ˆì´í„°)** - ë‹¤ìŒ ëª¨ë“  ê²½ìš°:
    - ìƒí™© ì„¤ëª…: "ì›ì´ëŠ” ê³„ë‹¨ì„ ì˜¬ëì–´ìš”."
    - ìºë¦­í„° í–‰ë™ ë¬˜ì‚¬: "ì„¤ë ˜ìœ¼ë¡œ ê°€ë“ì°¬ ì›ì´ì˜ ì—¬ì •!"
    - ë°°ê²½ ì„¤ëª…: "ì˜›ë‚  ì˜›ì ì—...", "ì–´ëŠ ë‚  ì•„ì¹¨..."
    - ê°ì • ë¬˜ì‚¬: "ì›ì´ëŠ” ê°€ìŠ´ì´ ë‘ê·¼ë‘ê·¼ ë›°ì—ˆì–´ìš”."

    **ìºë¦­í„° ìŒì„±** - ì˜¤ì§ ì§ì ‘ ëŒ€ì‚¬(ë”°ì˜´í‘œ ì•ˆ)ë§Œ!
    - child_male: ì†Œë…„ì´ ì§ì ‘ ë§í•  ë•Œ â†’ "ë‚´ê°€ í• ê²Œìš”!"
    - adult_male: ì„±ì¸ ë‚¨ì„±ì´ ì§ì ‘ ë§í•  ë•Œ â†’ "ê°€ì, ì›ì•„!"
    - elder_female: í• ë¨¸ë‹ˆê°€ ì§ì ‘ ë§í•  ë•Œ â†’ "ì˜ ë‹¤ë…€ì˜¤ë ´"

    ### ì‚¬ìš© ê°€ëŠ¥í•œ í™”ì ëª©ë¡:
    - **narrator**: ëª¨ë“  ë‚˜ë ˆì´ì…˜/ì„¤ëª… (ê¸°ë³¸ê°’!)
    - **child_male**: ì†Œë…„ì˜ ì§ì ‘ ëŒ€ì‚¬ ("...")
    - **child_female**: ì†Œë…€ì˜ ì§ì ‘ ëŒ€ì‚¬
    - **adult_male**: ì„±ì¸ ë‚¨ì„±ì˜ ì§ì ‘ ëŒ€ì‚¬
    - **adult_female**: ì„±ì¸ ì—¬ì„±ì˜ ì§ì ‘ ëŒ€ì‚¬
    - **elder_female**: í• ë¨¸ë‹ˆì˜ ì§ì ‘ ëŒ€ì‚¬
    - **elder_male**: í• ì•„ë²„ì§€ì˜ ì§ì ‘ ëŒ€ì‚¬
    - **young_female**: ì Šì€ ì—¬ì„±ì˜ ì§ì ‘ ëŒ€ì‚¬
    - **young_male**: ì Šì€ ë‚¨ì„±ì˜ ì§ì ‘ ëŒ€ì‚¬
    - **animal**: ë™ë¬¼ì˜ ì§ì ‘ ëŒ€ì‚¬
    - **fairy**: ìš”ì •/ë§ˆë²•ì‚¬ì˜ ì§ì ‘ ëŒ€ì‚¬
    - **none**: ë¹ˆ ìë§‰ (ê·¸ë¦¼ë§Œ ìˆëŠ” í˜ì´ì§€)

    ### ì˜ˆì‹œ (ì¤‘ìš”!):
    - "ì›ì´ëŠ” ìˆ¨ì„ í—ë–¡ì´ë©° ê³„ë‹¨ì„ ì˜¬ëì–´ìš”." â†’ **narrator** (ìƒí™© ì„¤ëª…)
    - "ë´‰í™©ì‚° ìˆ²ê¸¸ì„ ë›°ì–´ê°€ëŠ” ì›ì´!" â†’ **narrator** (í–‰ë™ ë¬˜ì‚¬)
    - "ì„¤ë ˜ìœ¼ë¡œ ê°€ë“ì°¬ ì›ì´ì˜ ì—¬ì •ì´ ì‹œì‘ë˜ì—ˆì–´ìš”." â†’ **narrator** (ë‚˜ë ˆì´ì…˜)
    - ì›ì´ê°€ "ì €ë„ ê°™ì´ ê°€ë„ ë ê¹Œìš”?"ë¼ê³  ë§í–ˆì–´ìš” â†’ **child_male** (ì§ì ‘ ëŒ€ì‚¬)
    - "ê³¼ì—° ì–´ë–»ê²Œ ë ê¹Œìš”?" â†’ **narrator** (ê¶ê¸ˆì¦ ìœ ë°œ)

    ###  í”í•œ ì‹¤ìˆ˜:
    - "ì›ì´ëŠ” ì„¤ë ˆëŠ” ë§ˆìŒì„ ê°ì¶œ ìˆ˜ ì—†ì—ˆì–´ìš”." â†’ narrator (O) / child_male (X)
    - "ê°€íŒŒë¥¸ ê³„ë‹¨ì„ ì˜¤ë¥´ëŠ” ì›ì´!" â†’ narrator (O) / child_male (X)

    ---

    ## JSON ì‘ë‹µ í˜•ì‹
    {{
    "subtitles": [
        {{"text": "ì²œë…„ê³ ì°° ë¬´ëŸ‰ìˆ˜ì „ìœ¼ë¡œ í–¥í•˜ëŠ” ê¸¸, ì„¤ë ˜ìœ¼ë¡œ ê°€ë“ì°¬ ì›ì´ì˜ ì—¬ì •ì´ ì‹œì‘ë˜ì—ˆì–´ìš”!", "speaker": "narrator"}},
        {{"text": "ê°€íŒŒë¥¸ ë°±íŒ” ê³„ë‹¨ì„ ì˜¤ë¥´ëŠ” ì›ì´, ìˆ¨ì´ í„±ê¹Œì§€ ì°¨ì˜¬ëì§€ìš”!", "speaker": "narrator"}},
        {{"text": "ê·¸ë•Œ, ëˆˆì•ì— ì›…ì¥í•œ ë¬´ëŸ‰ìˆ˜ì „ì´ ë‚˜íƒ€ë‚¬ì–´ìš”!", "speaker": "narrator"}},
        {{"text": "ê·¸ë¦¬ê³  ê·¸ê³³ì—ì„œ ìš´ëª…ì²˜ëŸ¼ ë§Œë‚œ í•œ ì‚¬ëŒ... ë°”ë¡œ ì™•ê±´ì´ì—ˆì–´ìš”.", "speaker": "narrator"}},
        {{"text": "ê³¼ì—° ì›ì´ì™€ ì™•ê±´ì˜ ë§Œë‚¨ì€ ì–´ë–¤ ì´ì•¼ê¸°ë¡œ ì´ì–´ì§ˆê¹Œìš”?", "speaker": "narrator"}}
    ]
    }}
    """

        response = client.chat.completions.create(
            model="gpt-5.2",  # GPT-5.2 for advanced context understanding (2025.12)
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )

        result = json.loads(response.choices[0].message.content)
        subtitles = result.get("subtitles", [])

        # ìë§‰ ê°œìˆ˜ê°€ ì¥ë©´ ìˆ˜ì™€ ë‹¤ë¥´ë©´ ì¡°ì •
        while len(subtitles) < num_scenes:
            subtitles.append({"text": "", "speaker": "none"})
        if len(subtitles) > num_scenes:
            subtitles = subtitles[:num_scenes]

        # ìœ íš¨í•œ í™”ì ëª©ë¡ (ê²€ì¦ìš©)
        VALID_SPEAKERS = {
            "narrator", "child", "child_male", "child_female",
            "elder_female", "elder_male", "adult_female", "adult_male",
            "young_female", "young_male", "animal", "fairy", "none"
        }

        # ê° í•­ëª©ì´ dictì¸ì§€ í™•ì¸í•˜ê³  ì •ê·œí™” + ê²€ì¦
        normalized = []
        for item in subtitles:
            if isinstance(item, dict):
                text = item.get("text", "")
                speaker = item.get("speaker", "narrator")

                # ìœ íš¨ì„± ê²€ì¦ - ì˜ëª»ëœ í™”ìëŠ” narratorë¡œ í´ë°±
                if speaker not in VALID_SPEAKERS:
                    print(f"ì˜ˆìƒì¹˜ ëª»í•œ í™”ì '{speaker}' â†’ narratorë¡œ ë³€ê²½")
                    speaker = "narrator"

                normalized.append({"text": text, "speaker": speaker})
            elif isinstance(item, str):
                # ì´ì „ í˜•ì‹ í˜¸í™˜ (ë¬¸ìì—´ë§Œ ìˆëŠ” ê²½ìš°)
                normalized.append({
                    "text": item,
                    "speaker": "narrator" if item else "none"
                })
            else:
                normalized.append({"text": "", "speaker": "none"})

        return normalized


    # í•˜ìœ„ í˜¸í™˜ìš© ë˜í¼ (ê¸°ì¡´ ì½”ë“œ ì§€ì›)
    def generate_trailer_subtitles(page_texts: list[tuple[str, str]], duration_per_clip: int):
        """ê¸°ì¡´ í•¨ìˆ˜ í˜¸í™˜ - í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜"""
        results = generate_trailer_subtitles_with_speakers(page_texts, duration_per_clip)
        return [item["text"] for item in results]


    # --------------------------------
    # ğŸ—‚ Session State (3ë‹¨ê³„ ë°ì´í„° ì €ì¥ìš©)
    # --------------------------------
    # ë‹¨ê³„ë³„ ë°ì´í„°ë¥¼ ì €ì¥í•  ê³µê°„ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    if "proc_uid" not in st.session_state:
        st.session_state.proc_uid = None      # ì „ì²´ í”„ë¡œì„¸ìŠ¤ ê³µìœ  ID
    if "step1_scripts" not in st.session_state:
        st.session_state.step1_scripts = None # ëŒ€ë³¸ ë°ì´í„° [{"text":..., "speaker":...}]
    if "step2_audio" not in st.session_state:
        st.session_state.step2_audio = None   # ì˜¤ë””ì˜¤ ê²½ë¡œ ë° ê¸¸ì´ [{"path":..., "duration":...}]

    # --------------------------------
    # â‘¢ ì‹¤í–‰ íŒŒíŠ¸ (3ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤)
    # --------------------------------
    st.divider()
    st.subheader("â‘¢ ìƒì„± í”„ë¡œì„¸ìŠ¤")

    # =========================================================
    # [STEP 1] ëŒ€ë³¸ ì´ˆì•ˆ ìƒì„± (GPT)
    # =========================================================
    st.markdown("#### 1ï¸ ëŒ€ë³¸(Script) ìƒì„± ë° ìˆ˜ì •")

    if st.button("1ë‹¨ê³„: AI ëŒ€ë³¸ ì´ˆì•ˆ ìƒì„±", type="primary"):
        # 1. ê³ ìœ  ID ìƒì„±
        st.session_state.proc_uid = uuid.uuid4().hex[:8]
        
        st.info("ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ëŒ€ë³¸ê³¼ í™”ìë¥¼ ì„¤ì •í•©ë‹ˆë‹¤...")

        # 1-1. í…ìŠ¤íŠ¸ ì¶”ì¶œ
        page_texts = []
        for name in st.session_state.selected_pages:
            text = extract_text_for_image(name, txt_file)
            page_texts.append((name, text))
        
        # ì„¸ì…˜ì— ì›ë³¸ í…ìŠ¤íŠ¸ ì €ì¥ (ë‚˜ì¤‘ì— ì°¸ê³ ìš©)
        st.session_state.raw_texts = page_texts

        # 1-2. OpenAI ëŒ€ë³¸ ìƒì„±
        subtitle_data = generate_trailer_subtitles_with_speakers(page_texts, DEFAULT_DURATION)
        
        # ê²°ê³¼ ì €ì¥
        st.session_state.step1_scripts = subtitle_data
        
        # 2, 3ë‹¨ê³„ ë°ì´í„° ì´ˆê¸°í™” (ìƒˆë¡œ ìƒì„±í–ˆìœ¼ë¯€ë¡œ)
        st.session_state.step2_audio = None
        st.rerun()

    # ---------------------------------------------------------
    # [STEP 1.5] ëŒ€ë³¸ ê²€í†  ë° ìˆ˜ì • UI (1ë‹¨ê³„ ì™„ë£Œ ì‹œ í‘œì‹œ)
    # ---------------------------------------------------------
    if st.session_state.step1_scripts is not None:
        st.success(" ëŒ€ë³¸ ì´ˆì•ˆì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚´ìš©ì„ ìˆ˜ì •í•˜ê³  2ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ì„¸ìš”.")
        
        # ìˆ˜ì •ëœ ë‚´ìš©ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ (UI ë Œë”ë§ìš©ì´ ì•„ë‹ˆë¼ ì‹¤ì œ ë°ì´í„° ì €ì¥ìš©)
        # Streamlitì€ ìœ„ì ¯ ê°’ì„ ë°”ë¡œ ì„¸ì…˜ì— ë°˜ì˜í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, formì´ë‚˜ ì½œë°±ì„ ì“°ê±°ë‚˜
        # ì•„ë˜ì²˜ëŸ¼ í™”ë©´ì— ë¿Œë ¤ì§„ widgetì˜ ê°’ì„ ë‚˜ì¤‘ì— ì½ì–´ì™€ì•¼ í•©ë‹ˆë‹¤.
        
        with st.expander(" ëŒ€ë³¸ ìˆ˜ì •í•˜ê¸° (ì—¬ê¸°ë¥¼ í¼ì³ì„œ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”)", expanded=True):
            updated_scripts = []
            
            # ì¥ë©´ë³„ ì…ë ¥ì°½ í‘œì‹œ
            for i, item in enumerate(st.session_state.step1_scripts):
                img_name = st.session_state.selected_pages[i]
                
                st.markdown(f"**ì¥ë©´ {i+1}: {img_name}**")
                col_img, col_text, col_spk = st.columns([1, 3, 1])
                
                with col_img:
                    # ì¸ë„¤ì¼ í‘œì‹œ
                    img_obj = next((img for n, img in st.session_state.loaded_images if n == img_name), None)
                    if img_obj: st.image(img_obj)
                
                with col_text:
                    # í…ìŠ¤íŠ¸ ìˆ˜ì • (keyë¥¼ ì§€ì •í•˜ì—¬ ê°’ì„ ìœ ì§€)
                    new_text = st.text_area(
                        label="ëŒ€ì‚¬ (Subtitle)",
                        value=item["text"],
                        key=f"script_text_{i}",
                        height=70
                    )
                
                with col_spk:
                    # í™”ì ìˆ˜ì •
                    speakers_list = ["narrator", "child_male", "child_female", "adult_male", "adult_female", "elder_male", "elder_female", "young_male", "young_female", "animal", "none"]
                    
                    # ê¸°ì¡´ í™”ìê°€ ëª©ë¡ì— ì—†ìœ¼ë©´ ì¶”ê°€
                    current_spk = item["speaker"]
                    if current_spk not in speakers_list:
                        speakers_list.append(current_spk)
                        
                    new_speaker = st.selectbox(
                        label="í™”ì (Speaker)",
                        options=speakers_list,
                        index=speakers_list.index(current_spk),
                        key=f"script_spk_{i}"
                    )
                
                st.divider()

        # =========================================================
        # [STEP 2] TTS ìŒì„± ìƒì„±
        # =========================================================
        st.markdown("#### 2ï¸ TTS ìŒì„± ìƒì„± ë° ë¯¸ë¦¬ë“£ê¸°")
        
        if st.button("2ë‹¨ê³„: ìˆ˜ì •ëœ ëŒ€ë³¸ìœ¼ë¡œ TTS ìƒì„±", type="primary"):
            OUT = Path("outputs"); OUT.mkdir(exist_ok=True)
            uid = st.session_state.proc_uid
            
            # UI ì…ë ¥ê°’(ìˆ˜ì •ëœ ê°’)ì„ ì½ì–´ì„œ ë¦¬ìŠ¤íŠ¸ ì¬êµ¬ì„±
            final_scripts = []
            for i in range(len(st.session_state.step1_scripts)):
                final_scripts.append({
                    "text": st.session_state[f"script_text_{i}"],
                    "speaker": st.session_state[f"script_spk_{i}"]
                })
            
            # ìˆ˜ì •ëœ ëŒ€ë³¸ ì—…ë°ì´íŠ¸
            st.session_state.step1_scripts = final_scripts
            
            st.info(" TTS ìŒì„±ì„ ìƒì„±í•˜ê³  ê¸¸ì´ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤...")
            
            # TTS ìƒì„±
            texts = [s["text"] for s in final_scripts]
            speakers = [s["speaker"] for s in final_scripts]
            
            audio_paths = generate_audio_for_subtitles(texts, OUT, uid, speakers=speakers)
            
            # ê¸¸ì´ ì¸¡ì •
            audio_data = []
            for path in audio_paths:
                if path and Path(path).exists():
                    dur = get_audio_duration(str(path))
                    audio_data.append({"path": path, "duration": dur})
                else:
                    audio_data.append({"path": None, "duration": None})
                    
            st.session_state.step2_audio = audio_data
            st.rerun()

    # ---------------------------------------------------------
    # [STEP 2.5] ì˜¤ë””ì˜¤ ê²€í†  UI (ìˆ˜ì •ëœ ì½”ë“œ)
    # ---------------------------------------------------------
    if st.session_state.step2_audio is not None:
        st.success(" ìŒì„± ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë“¤ì–´ë³´ê³  ì´ìƒ ì—†ìœ¼ë©´ ì˜ìƒì„ ìƒì„±í•˜ì„¸ìš”.")
        
        with st.expander("ğŸ§ ìŒì„± ë¯¸ë¦¬ë“£ê¸°", expanded=True):
            for i, audio_info in enumerate(st.session_state.step2_audio):
                path = audio_info["path"]
                dur = audio_info["duration"]
                script = st.session_state.step1_scripts[i]["text"]
                
                # durê°€ Noneì¼ ê²½ìš° 0.0ìœ¼ë¡œ í‘œì‹œ
                dur_display = f"{dur:.1f}" if dur is not None else "0.0"
                
                st.write(f"**ì¥ë©´ {i+1}** ({dur_display}ì´ˆ) : {script}")
                
                if path and os.path.exists(path):
                    st.audio(path)
                else:
                    st.caption("ìŒì„± ì—†ìŒ (ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” ë¬´ìŒ)")

        # =========================================================
        # [STEP 3] Runway ì˜ìƒ ìƒì„± ë° ìµœì¢… ë³‘í•©
        # =========================================================
        st.divider()
        st.markdown("#### 3ï¸Runway ì˜ìƒ ìƒì„± (ìµœì¢…)")
        st.warning(" ì´ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ Runway  í¬ë ˆë”§ì´ ì°¨ê°ë©ë‹ˆë‹¤!")
    
        if st.button("3ë‹¨ê³„: Runway ì˜ìƒ ìƒì„± ë° í•©ì¹˜ê¸°", type="primary"):
            uid = st.session_state.proc_uid
            OUT = Path("outputs")
            video_paths = []
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            total = len(st.session_state.selected_pages)
            
            # 1. ì˜ìƒ ìƒì„±
            for i, name in enumerate(st.session_state.selected_pages):
                status_text.text(f"[{i+1}/{total}] '{name}' ì˜ìƒ ìƒì„± ì¤‘...")
                
                img_path = folder / name
                tts_dur = st.session_state.step2_audio[i]["duration"]
                
                # ê¸¸ì´ ê²°ì •
                if tts_dur is None:
                    runway_dur = DEFAULT_DURATION
                elif tts_dur <= 5.0:
                    runway_dur = 5
                else:
                    runway_dur = 10
                
                # Runway í˜¸ì¶œ
                try:
                    result = generate_video_from_image(str(img_path), PROMPT, runway_dur)
                    video_url = extract_video_url(result)
                    
                    raw_path = OUT / f"clip_{i:02d}_{uid}_raw.mp4"
                    download_video(video_url, raw_path)
                    
                    # ìë¥´ê¸°
                    out_path = OUT / f"clip_{i:02d}_{uid}.mp4"
                    if tts_dur and tts_dur < runway_dur:
                        trim_video_to_duration(str(raw_path), tts_dur, str(out_path))
                    else:
                        shutil.copy(str(raw_path), str(out_path))
                    video_paths.append(out_path)
                    
                except Exception as e:
                    st.error(f"ì˜ìƒ ìƒì„± ì‹¤íŒ¨ ({name}): {e}")
                    video_paths.append(None)
                
                progress_bar.progress((i + 1) / total)
                
            # 2. í•©ì„±
            status_text.text("ìë§‰ ë° ì˜¤ë””ì˜¤ í•©ì„± ì¤‘...")
            final_clips = []
            
            for i, vid in enumerate(video_paths):
                if vid is None: continue

                sub = st.session_state.step1_scripts[i]["text"]
                audio = st.session_state.step2_audio[i]["path"]
                img_name = st.session_state.selected_pages[i]

                # ìë§‰
                sub_out = str(vid).replace(".mp4", "_sub.mp4")
                add_subtitle_to_video(str(vid), sub, sub_out, scene_index=i)

                # ì˜¤ë””ì˜¤ (BGM í¬í•¨ - í˜ì´ì§€ë³„ ìë™ ë§¤ì¹­)
                final_out = sub_out.replace("_sub.mp4", "_audio.mã…p4")
                if audio and os.path.exists(audio):
                    # í•´ë‹¹ í˜ì´ì§€ì˜ BGM ì°¾ê¸°
                    page_bgm = None
                    if use_bgm:
                        page_bgm = get_bgm_for_page(img_name, BGM_DIR)

                    if page_bgm and page_bgm.exists():
                        add_audio_to_video(sub_out, audio, final_out, bgm_path=str(page_bgm), bgm_volume=bgm_volume)
                        print(f"   Scene {i+1} ({img_name}): BGM '{page_bgm.name}' ì ìš©")
                    else:
                        add_audio_to_video(sub_out, audio, final_out)
                        if use_bgm:
                            print(f"   Scene {i+1} ({img_name}): ë§¤ì¹­ë˜ëŠ” BGM ì—†ìŒ")
                else:
                    shutil.copy(sub_out, final_out) 

                final_clips.append(final_out)
                
            # 3. ìµœì¢… ë³‘í•©
            status_text.text("ìµœì¢… íŒŒì¼ ì €ì¥ ì¤‘...")
            final_video = OUT / f"short_final_{uid}.mp4"
            concat_videos_with_audio(final_clips, str(final_video))
            
            progress_bar.progress(100)
            status_text.text("ì™„ë£Œ!")
            
            st.success(" ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.video(str(final_video))
            
            with open(final_video, "rb") as f:
                st.download_button(" ìµœì¢… ì˜ìƒ ë‹¤ìš´ë¡œë“œ", f, file_name=f"short_final_{uid}.mp4")

#-------------------------------
# B. í…ìŠ¤íŠ¸ ë¶„ì„ ê¸°ë°˜ ì œì‘
#-----------------------------
elif mode == "(ì‹ ê·œ) í…ìŠ¤íŠ¸ ë¶„ì„ ê¸°ë°˜ ì˜ˆê³ í¸ ì œì‘":
    b_text_based.run_text_analysis_mode(client, folder, txt_file)
    